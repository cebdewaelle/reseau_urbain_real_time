Extract -> 
dags1 dag_download_unzip_archive_gtfs_statiques (daily):
zip statique (https://www.data.gouv.fr/api/1/datasets/r/f5678ab2-c863-4b48-ba1f-9021c7d97634)
- tache0: téléchargement du zip gtfs statique dans /opt/airflow/data/in/{date_du_jour: AAAAMMJJ}
- tache1: unzip du fichier gtfs.zip dans /opt/airflow/data/in/{date_du_jour: AAAAMMJJ}/gtfs/
- tache2: renommage du fichier gtfs.zip en gtfs{date_du_jour: AAAAMMJJ}.zip puis déplacement de celui-ci vers le répertoire /opt/airflow/data/archives/


dags2: dag_download_gtfs_realtime (20 minutes):
temps réel (https://www.data.gouv.fr/api/1/datasets/r/5f571595-aef1-480f-acde-b9315d9f5f3b)
- tache: téléchargement du zip gtfs dans /opt/airflow/warehouse/
- tache: unzip du fichier gtfs.zip dans /opt/airflow/warehouse/20250903/


Transform ->
dags3:
- tache: lire les fichiers.txt du répertoire /opt/airflow/warehouse/20250903/
        avec pandas + insertion du contenu dans duckdb


Load ->
dags4:
- tache: exporter les données nécessaires dans un/des fichiers csv à enregistrer dans /opt/airflow/exports/20250903/
